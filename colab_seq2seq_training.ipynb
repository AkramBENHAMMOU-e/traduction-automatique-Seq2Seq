{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq English–French Translation (Colab)\n",
    "\n",
    "Notebook d'entraînement pour le **Sujet 11 : Traduction automatique simplifiée avec Seq2Seq**.\n",
    "\n",
    "- Modèle : encodeur–décodeur LSTM (Seq2Seq) en PyTorch.\n",
    "- Données : corpus de paires de phrases anglais–français (fichier CSV).\n",
    "- Objectif : entraîner un mini-traducteur et tester quelques phrases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dépendances de base\n",
    "!pip install -q torch pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Charger les données\n",
    "# Option simple : uploader manuellement le fichier CSV depuis votre machine.\n",
    "# Le fichier doit contenir deux colonnes : colonne 0 = anglais, colonne 1 = français.\n",
    "# Exemple : utilisez le dataset Kaggle \"Language Translation English-French\" et exportez un CSV.\n",
    "\n",
    "from google.colab import files\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Veuillez sélectionner votre fichier CSV (ex: eng_-french.csv)...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# On prend le premier fichier uploadé\n",
    "csv_name = list(uploaded.keys())[0]\n",
    "print(f\"Fichier reçu : {csv_name}\")\n",
    "\n",
    "df = pd.read_csv(io.BytesIO(uploaded[csv_name]))\n",
    "DATA_PATH = \"eng_-french_colab.csv\"\n",
    "df.to_csv(DATA_PATH, index=False)\n",
    "print(f\"Données sauvegardées sous {DATA_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Prétraitement des données et dataset PyTorch\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "PAD_token = 3\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\", 3: \"PAD\"}\n",
    "        self.n_words = 4  # Count SOS, EOS, UNK, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    # Séparer la ponctuation\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def read_data(path, limit=None):\n",
    "    df_local = pd.read_csv(path)\n",
    "    if limit:\n",
    "        df_local = df_local.head(limit)\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(len(df_local)):\n",
    "        eng = normalizeString(str(df_local.iloc[i, 0]))\n",
    "        fra = normalizeString(str(df_local.iloc[i, 1]))\n",
    "        pairs.append([eng, fra])\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def filterPair(p, max_length=15):\n",
    "    return len(p[0].split(' ')) < max_length and len(p[1].split(' ')) < max_length\n",
    "\n",
    "def filterPairs(pairs, max_length=15):\n",
    "    return [pair for pair in pairs if filterPair(pair, max_length)]\n",
    "\n",
    "def prepareData(path, limit=None):\n",
    "    pairs = read_data(path, limit)\n",
    "    print(f\"Read {len(pairs)} sentence pairs\")\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n",
    "\n",
    "    input_lang = Lang(\"eng\")\n",
    "    output_lang = Lang(\"fra\")\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index.get(word, UNK_token) for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = [SOS_token] + indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long)\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, pairs, input_lang, output_lang):\n",
    "        self.pairs = pairs\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        input_tensor = tensorFromSentence(self.input_lang, pair[0])\n",
    "        target_tensor = tensorFromSentence(self.output_lang, pair[1])\n",
    "        return input_tensor, target_tensor, pair[0], pair[1]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_tensors, target_tensors, _, _ = zip(*batch)\n",
    "\n",
    "    input_lengths = [len(tensor) for tensor in input_tensors]\n",
    "    target_lengths = [len(tensor) for tensor in target_tensors]\n",
    "\n",
    "    input_tensors_padded = torch.nn.utils.rnn.pad_sequence(input_tensors, padding_value=PAD_token)\n",
    "    target_tensors_padded = torch.nn.utils.rnn.pad_sequence(target_tensors, padding_value=PAD_token)\n",
    "\n",
    "    return input_tensors_padded, target_tensors_padded, input_lengths, target_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Modèle Seq2Seq (encodeur–décodeur LSTM)\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_vocab_size, embedding_dim, hidden_size, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_vocab_size, embedding_dim, padding_idx=PAD_token)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "\n",
    "    def forward(self, src, src_lengths):\n",
    "        # src: (src_len, batch_size)\n",
    "        embedded = self.embedding(src)\n",
    "        packed = pack_padded_sequence(embedded, src_lengths, enforce_sorted=False)\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed)\n",
    "        outputs, _ = pad_packed_sequence(packed_outputs)\n",
    "        return outputs, (hidden, cell)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_vocab_size, embedding_dim, hidden_size, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_vocab_size, embedding_dim, padding_idx=PAD_token)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size, output_vocab_size)\n",
    "\n",
    "    def forward(self, input_step, hidden, cell):\n",
    "        # input_step: (batch_size,)\n",
    "        input_step = input_step.unsqueeze(0)  # (1, batch_size)\n",
    "        embedded = self.embedding(input_step)  # (1, batch_size, embedding_dim)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        predictions = self.fc_out(outputs.squeeze(0))  # (batch_size, vocab_size)\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, src_lengths, trg, teacher_forcing_ratio=0.5):\n",
    "        # src: (src_len, batch_size)\n",
    "        # trg: (trg_len, batch_size)\n",
    "        batch_size = trg.size(1)\n",
    "        trg_len = trg.size(0)\n",
    "        vocab_size = self.decoder.output_vocab_size\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, vocab_size, device=self.device)\n",
    "\n",
    "        _, (hidden, cell) = self.encoder(src, src_lengths)\n",
    "\n",
    "        # Premier token d'entrée du décodeur : <SOS>\n",
    "        input_step = trg[0, :]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input_step, hidden, cell)\n",
    "            outputs[t] = output\n",
    "\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            input_step = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Entraînement du modèle Seq2Seq\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Hyperparamètres\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT = 0.1\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 5          # Vous pouvez augmenter si vous avez le temps\n",
    "LEARNING_RATE = 1e-3\n",
    "TEACHER_FORCING_RATIO = 0.5\n",
    "GRAD_CLIP = 1.0\n",
    "\n",
    "# Limitez le nombre de paires pour aller plus vite (ex: 50_000) ou None pour tout\n",
    "LIMIT_PAIRS = 50000\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(DATA_PATH, limit=LIMIT_PAIRS)\n",
    "\n",
    "dataset = TranslationDataset(pairs, input_lang, output_lang)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "encoder = EncoderRNN(\n",
    "    input_vocab_size=input_lang.n_words,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    ").to(device)\n",
    "\n",
    "decoder = DecoderRNN(\n",
    "    output_vocab_size=output_lang.n_words,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=DROPOUT,\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_token)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "def train_epoch():\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        src, trg, src_lengths, _ = batch\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, src_lengths, trg, teacher_forcing_ratio=TEACHER_FORCING_RATIO)\n",
    "\n",
    "        # output: (trg_len, batch_size, vocab_size)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].reshape(-1, output_dim)\n",
    "        trg_flat = trg[1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg_flat)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch()\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch}/{N_EPOCHS} - loss: {train_loss:.4f} - time: {elapsed:.1f}s\")\n",
    "\n",
    "MODEL_PATH = \"seq2seq_en_fr_colab.pt\"\n",
    "torch.save(\n",
    "    {\n",
    "        \"encoder_state_dict\": encoder.state_dict(),\n",
    "        \"decoder_state_dict\": decoder.state_dict(),\n",
    "        \"input_lang\": input_lang,\n",
    "        \"output_lang\": output_lang,\n",
    "        \"config\": {\n",
    "            \"embedding_dim\": EMBEDDING_DIM,\n",
    "            \"hidden_size\": HIDDEN_SIZE,\n",
    "            \"num_layers\": NUM_LAYERS,\n",
    "            \"dropout\": DROPOUT,\n",
    "        },\n",
    "    },\n",
    "    MODEL_PATH,\n",
    ")\n",
    "print(f\"Modèle sauvegardé dans {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Fonction de traduction pour tester le modèle\n",
    "\n",
    "def translate_sentence(sentence, model, input_lang, output_lang, device, max_length=30):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        normalized = normalizeString(sentence)\n",
    "        src_tensor = tensorFromSentence(input_lang, normalized).to(device)\n",
    "        src_length = [src_tensor.size(0)]\n",
    "        src_tensor = src_tensor.unsqueeze(1)  # (seq_len, 1)\n",
    "\n",
    "        _, (hidden, cell) = model.encoder(src_tensor, src_length)\n",
    "        input_token = torch.tensor([SOS_token], dtype=torch.long, device=device)\n",
    "\n",
    "        decoded_tokens = []\n",
    "        for _ in range(max_length):\n",
    "            output, hidden, cell = model.decoder(input_token, hidden, cell)\n",
    "            top1 = output.argmax(1)\n",
    "            token_id = top1.item()\n",
    "            if token_id == EOS_token:\n",
    "                break\n",
    "            decoded_tokens.append(token_id)\n",
    "            input_token = top1\n",
    "\n",
    "    translated_words = [output_lang.index2word.get(idx, \"<UNK>\") for idx in decoded_tokens]\n",
    "    return \" \".join(translated_words)\n",
    "\n",
    "# Exemple rapide après entraînement :\n",
    "test_sentence = \"i am a student .\"\n",
    "print(\"Anglais :\", test_sentence)\n",
    "print(\"Français :\", translate_sentence(test_sentence, model, input_lang, output_lang, device))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

